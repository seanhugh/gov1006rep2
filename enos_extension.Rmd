---
title: "Enos Extension"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Install Required Packages
rm(list = ls())

library(ri)
library(RItools)
library(car)
library(xtable)
library(effects)
library(RColorBrewer)
library(gt)
library(knitr)
library(dplyr)
library(data.table)
library(rstanarm)
library(broom)
library(ggplot2)

# Load data

dat.all = read.csv('./csvData/pnas_data.csv')
dat.t1 = read.csv('./csvData/t1_data.csv')
dat.all.prime = read.csv('./csvData/prime_data.csv')

# Data loading for faces graphic
conf.dat = read.csv('./csvData/confederate_face_data.csv')
hisp.dat = read.csv('./csvData/hispanic_face_data.csv')
white.dat = read.csv('./csvData/white_face_data.csv')

```


```{r DataCreation, echo = FALSE, include = FALSE}

# Create a new tibble summarized_data

summarized_data <- dat.all %>% 
  
  # filter out all NA instances
  
  filter(!is.na(numberim.x) &
         !is.na(numberim.y) &
         !is.na(Remain.x) &
         !is.na(Remain.y) &
         !is.na(Englishlan.x) &
         !is.na(Englishlan.y)) %>% 
  
  # Create a new variable that equals the sum of each of the repsonse columns
  # The three columns are: "numberim", "Remain", "Englishlan"
  
  mutate(sumx = numberim.x + Remain.x + Englishlan.x,
                   sumy = numberim.y + Remain.y + Englishlan.y) %>% 
  
  # Create a new variable total_sum that equals the difference from the second
  # round of interviews (.y) to the first round of interviews (.x)
  
  mutate(view_change = sumy - sumx) 
  
  # select the variables that we will use in our regression

# Build a Bayesian Linear Regression of the data

data_model <- stan_glm(view_change ~ treatment, data = summarized_data)

# We will now build a bayesian linear regression and add in some extra variables

data_model2 <- stan_glm(view_change ~ treatment + age + male + republican + income + romney.voter, data = summarized_data)
  
# Save the model parameters

tidy_coef <- tidy(data_model2)

# Extract intercept and slope

model_intercept <- tidy_coef$estimate[1]

# Remove the first row of the dataset now that we have extracted the slope

tidy_coef2 <- tidy_coef[-1,]

```

## Abstract

I use the Harvard Dataverse data to explore the data and findings from the paper ["Causal Effect of Intergroup Contact on Exclusionary Attitudes"](https://scholar.harvard.edu/files/renos/files/enostrains.pdf)[1].

## Details

I want to run a more complex bayesian linear model on the data to explore how significant
some of the factors were in predicting the conservative or liberal shift in the sibjects views over the course of the experiment. Conservative or Liberal responses to the questions were judged on a scale from 1 - 5 (with 5 being the most conservative). I created a new variable that accounted for this change across the 3 different "questions" that were tracked over the course of the experiment: numberim, remain, and englishlan. This new number is positive when the subject shifted to become more conservative over the weeklong period, and is negative when the subject shifted to become more liberal over the period. The following is a bar graph demonstrating the estimates for the slope of different variables that were entered into the model (Model was created using stan_glm). Note how treatment has the largest magnitude.

```{r DataModeling, echo = FALSE}

# Create the plot

ggplot(tidy_coef2, aes(x = term, y = estimate)) +
  geom_bar(stat="identity") +
  ggtitle("Estimates of Conditions from Bayesian Linear Regression (Intercept = 1)") +
  labs(subtitle = "This graph shows the output of the strat_glm function on the projects \n dataset. It can be seen that the treatment condition has the largest impact \n of any of the given variables.") +
  labs(x = "Variable", y = "Estimate")


```